# üì± Spam SMS Detection

**CodSoft Machine Learning Internship - Task 4**  
**Author:** Chandan Kumar  
**Batch:** December 2025 B68

---

## üéØ Project Overview

An AI-powered SMS spam detection system using Natural Language Processing and Machine Learning. The system provides real-time classification of SMS messages as spam or legitimate (ham) with detailed probability analysis and an interactive web interface.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![Status](https://img.shields.io/badge/Status-Complete-success.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-97%25-brightgreen.svg)

---

## ‚ú® Features

- ü§ñ **Real-time SMS Classification** - Instant spam/ham prediction
- üìä **Probability Analysis** - Detailed confidence scores and probabilities
- üé® **Modern Web Interface** - Clean, responsive UI design
- üîç **NLP Pipeline** - Advanced text preprocessing and feature extraction
- üìà **High Accuracy** - ~97% classification accuracy
- üí° **Sample Messages** - Pre-loaded examples for testing
- üì± **Mobile Responsive** - Works seamlessly on all devices
- ‚ö° **Fast Inference** - Real-time predictions

---

## üìÅ Project Structure

```
codsoft_04/                            # Task 4 Root Directory
‚îÇ
‚îú‚îÄ‚îÄ artifacts/                         # Generated (NOT in repo)
‚îÇ   ‚îú‚îÄ‚îÄ eda_summary.json              # EDA insights
‚îÇ   ‚îú‚îÄ‚îÄ training_metrics.json         # Model metrics
‚îÇ   ‚îî‚îÄ‚îÄ classification_report.txt     # Detailed report
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Dataset (NOT in repo)
‚îÇ   ‚îú‚îÄ‚îÄ spam.csv                      # Original dataset
‚îÇ   ‚îî‚îÄ‚îÄ spam_processed.csv            # Processed data
‚îÇ
‚îú‚îÄ‚îÄ frontend/                          # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ index.html                    # Main web interface
‚îÇ   ‚îú‚îÄ‚îÄ style.css                     # Styling
‚îÇ   ‚îî‚îÄ‚îÄ script.js                     # JavaScript logic
‚îÇ
‚îú‚îÄ‚îÄ images/                            # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ spam_distribution.png         # Class distribution
‚îÇ   ‚îú‚îÄ‚îÄ wordcloud_ham.png             # Ham word cloud
‚îÇ   ‚îú‚îÄ‚îÄ wordcloud_spam.png            # Spam word cloud
‚îÇ   ‚îú‚îÄ‚îÄ message_length_analysis.png   # Length analysis
‚îÇ   ‚îú‚îÄ‚îÄ top_spam_words.png            # Most common spam words
‚îÇ   ‚îú‚îÄ‚îÄ top_ham_words.png             # Most common ham words
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png          # Model confusion matrix
‚îÇ   ‚îú‚îÄ‚îÄ model_performance.png         # Performance metrics
‚îÇ   ‚îî‚îÄ‚îÄ probability_distribution.png  # Probability analysis
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Trained models (NOT in repo)
‚îÇ   ‚îú‚îÄ‚îÄ spam_detector_model.pkl       # Trained model
‚îÇ   ‚îî‚îÄ‚îÄ tfidf_vectorizer.pkl          # TF-IDF vectorizer
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.ipynb           # EDA & preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ model_training.ipynb          # Model training & evaluation
‚îÇ
‚îú‚îÄ‚îÄ app.py                             # Flask backend
‚îú‚îÄ‚îÄ README.md                          # This file
‚îî‚îÄ‚îÄ requirements.txt                   # Python dependencies
```

**‚ö†Ô∏è Important Notes:**
- `artifacts/`, `data/`, and `models/` folders are **NOT** pushed to GitHub due to file size limitations
- These folders are automatically generated when you run the notebooks
- `images/` folder **IS** included and contains all visualization PNG files
- Download dataset separately from the source before running

---

## üöÄ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- pip package manager
- 4GB RAM minimum
- Dataset downloaded separately

### 1Ô∏è‚É£ Clone Repository

```bash
git clone https://github.com/chandank013/CODSOFT.git
cd CODSOFT/codsoft_04
```

### 2Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

**Or install manually:**
```bash
pip install flask numpy pandas scikit-learn nltk matplotlib seaborn jupyter
```

**Required Libraries:**
- flask >= 2.0.0
- numpy >= 1.21.0
- pandas >= 1.3.0
- scikit-learn >= 1.0.0
- nltk >= 3.6.0
- matplotlib >= 3.4.0
- seaborn >= 0.11.0
- jupyter >= 1.0.0

### 3Ô∏è‚É£ Download NLTK Data

```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```

**Or run this in terminal:**
```bash
python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt')"
```

### 4Ô∏è‚É£ Prepare Dataset

- Download `spam.csv` from SMS Spam Collection Dataset
- Create `data/` folder: `mkdir data`
- Place `spam.csv` in the `data/` folder

### 5Ô∏è‚É£ Run Notebooks

```bash
jupyter notebook
```

**Run in order:**
1. `preprocessing.ipynb` - EDA and preprocessing
2. `model_training.ipynb` - Model training

This will generate:
- Processed data in `artifacts/`
- Trained models in `models/`
- Visualizations in `images/`

### 6Ô∏è‚É£ Run the Application

```bash
python app.py
```

### 7Ô∏è‚É£ Open in Browser

Navigate to: **http://127.0.0.1:5000**

The prediction interface will open automatically! üéâ

---

## üíª Usage

### Option 1: Run Jupyter Notebooks (Recommended)

**Step-by-step execution:**

1. **Start Jupyter Notebook**
```bash
jupyter notebook
```

2. **Run notebooks in order:**

   **a) Preprocessing (5-10 minutes)**
   ```
   notebooks/preprocessing.ipynb
   ```
   - Loads dataset from `data/` folder
   - Performs EDA
   - Creates visualizations (saved to `images/`)
   - Preprocesses text data
   - Saves artifacts to `artifacts/`
   
   **b) Model Training (5-10 minutes)**
   ```
   notebooks/model_training.ipynb
   ```
   - Trains Naive Bayes classifier
   - Evaluates model performance
   - Generates performance visualizations
   - Saves model to `models/`

### Option 2: Use Flask Web Interface

```bash
python app.py
```

Then open your browser: `http://localhost:5000`

**Web Interface Features:**
1. **Enter Message**: Type or paste any SMS message
2. **Analyze**: Click "üîÆ Analyze Message" button
3. **View Results**: See prediction, confidence, and probabilities
4. **Try Examples**: Click sample cards for quick testing

**Keyboard Shortcuts:**
- `Ctrl + Enter`: Analyze message
- Click sample cards to auto-fill

### Option 3: Python Script for Predictions

```python
import pickle
import re
import string
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# Load model and vectorizer
with open('../models/spam_detector_model.pkl', 'rb') as f:
    model = pickle.load(f)
with open('../models/tfidf_vectorizer.pkl', 'rb') as f:
    vectorizer = pickle.load(f)

# Preprocessing function
def preprocess_text(text):
    ps = PorterStemmer()
    stop_words = set(stopwords.words('english'))
    
    text = text.lower()
    text = re.sub(r'http\S+|www\S+', '', text)  # Remove URLs
    text = re.sub(r'\S+@\S+', '', text)  # Remove emails
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    tokens = text.split()
    tokens = [ps.stem(word) for word in tokens if word not in stop_words]
    
    return ' '.join(tokens)

# Make prediction
message = "WINNER!! You won $1000. Call now!"
processed = preprocess_text(message)
features = vectorizer.transform([processed])

prediction = model.predict(features)[0]
probability = model.predict_proba(features)[0]

print(f"Message: {message}")
print(f"Prediction: {'SPAM' if prediction == 1 else 'HAM'}")
print(f"Spam Probability: {probability[1]*100:.2f}%")
print(f"Ham Probability: {probability[0]*100:.2f}%")
```

### Option 4: API Endpoint

**POST /predict**

Request:
```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{"message": "Congratulations! You won $1000"}'
```

Response:
```json
{
    "success": true,
    "prediction": "Spam",
    "spam_probability": 95.5,
    "ham_probability": 4.5,
    "confidence": 95.5,
    "message_length": 45,
    "processed_length": 32
}
```

---

## üìä Results

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Logistic Regression (Baseline) | 96.52% | 98.97% | 73.28% | 84.21% |
| Logistic Regression (Tuned) | 97.68% | 97.35% | 83.97% | 90.16% |
| Naive Bayes (Baseline) | 96.81% | 99.00% | 75.57% | 85.71% |
| Naive Bayes (Tuned) | **97.97%** | **97.41%** | **86.26%** | **91.50%** |
| Linear SVM (Baseline) | 97.87% | 97.39% | 85.50% | 91.06% |
| Linear SVM (Tuned) | ‚è≥ Pending | ‚è≥ Pending | ‚è≥ Pending | ‚è≥ Pending |
| Random Forest (Tuned) | ‚è≥ Pending | ‚è≥ Pending | ‚è≥ Pending | ‚è≥ Pending |

---

**Best Model:** üèÜ **Naive Bayes (Tuned)**  
**Final Accuracy:** **97.97%**  
**Final F1-Score:** **91.50%**

---

### üìà Improvement from Tuning
- Logistic Regression: **+5.95% F1**
- Naive Bayes: **+5.79% F1**
- Linear SVM: ‚è≥ Pending

---

### Confusion Matrix

|  | Predicted Ham | Predicted Spam |
|---|---------------|----------------|
| **Actual Ham** | 1,089 | 21 |
| **Actual Spam** | 11 | 179 |

### What This Means

‚úÖ **For every 100 spam messages:**
- We correctly identify 94 as spam (Recall)
- We miss 6 spam messages (False Negatives)

‚úÖ **For every 100 spam predictions:**
- 96 are actually spam (Precision)
- 4 are false alarms (False Positives)

### Dataset Statistics

- **Total Messages**: 5,572
- **Spam Messages**: 747 (13.4%)
- **Ham Messages**: 4,825 (86.6%)
- **Average Message Length**: 80 characters
- **Vocabulary Size**: ~7,000 unique words

### Key Findings

**Top Spam Indicators:**
- Money-related words: "free", "win", "prize", "cash"
- Urgency words: "urgent", "now", "limited", "claim"
- Call-to-action: "call", "text", "click", "reply"
- Numbers and symbols: phone numbers, excessive punctuation

**Ham Characteristics:**
- Natural conversational language
- Personal pronouns: "you", "we", "your"
- Common words: "ok", "thanks", "meet", "tomorrow"
- No excessive capitalization or symbols

### Visualizations

All visualizations are saved in the `images/` folder:

1. **Spam Distribution** (`spam_distribution.png`)
   - Shows 13.4% spam, 86.6% ham
   - Class imbalance visualization

2. **Word Clouds** (`wordcloud_ham.png`, `wordcloud_spam.png`)
   - Visual representation of common words
   - Ham: "ok", "thanks", "love", "good"
   - Spam: "free", "win", "call", "prize"

3. **Message Length Analysis** (`message_length_analysis.png`)
   - Spam messages tend to be longer
   - Distribution comparison

4. **Top Words** (`top_spam_words.png`, `top_ham_words.png`)
   - Most frequent words in each category
   - Bar chart visualization

5. **Confusion Matrix** (`confusion_matrix.png`)
   - Detailed classification results
   - TP, FP, TN, FN breakdown

6. **Model Performance** (`model_performance.png`)
   - Accuracy, Precision, Recall, F1-Score
   - Visual metric comparison

7. **Probability Distribution** (`probability_distribution.png`)
   - Model confidence distribution
   - Prediction certainty analysis

---

## üî¨ Technical Details

### Dataset
- **Source**: SMS Spam Collection Dataset
- **Size**: 5,572 messages
- **Distribution**: 13.4% spam (747), 86.6% ham (4,825)
- **Format**: CSV with 'label' and 'message' columns

### NLP Pipeline

**1. Text Cleaning:**
- Lowercase conversion
- URL removal (`http`, `www`)
- Email address removal
- Special character removal
- Number normalization

**2. Tokenization:**
- Word splitting
- Whitespace handling

**3. Stopword Removal:**
- Filter common words ("the", "is", "and")
- NLTK English stopwords

**4. Stemming:**
- Porter Stemmer for root words
- "running" ‚Üí "run", "better" ‚Üí "better"

**5. Vectorization:**
- TF-IDF (Term Frequency-Inverse Document Frequency)
- Max features: 3000
- N-gram range: (1, 2) - unigrams and bigrams
- Min document frequency: 2

### Machine Learning Model

**Algorithm:** Multinomial Naive Bayes
- **Why Naive Bayes?**
  - Excellent for text classification
  - Fast training and prediction
  - Works well with high-dimensional data
  - Probabilistic predictions
  - Good for imbalanced datasets

**Parameters:**
- Alpha (smoothing): 1.0
- Fit prior: True

**Training:**
- Train-test split: 80-20
- Stratified sampling to preserve class distribution

---

## üé® Web Interface Components

### 1. Input Section
- **Text Area**: Large input field for SMS messages
- **Character Counter**: Real-time character count
- **Action Buttons**: 
  - Analyze Message (primary)
  - Clear (secondary)

### 2. Results Display
- **Status Badge**: 
  - üö® SPAM DETECTED (red)
  - ‚úÖ LEGITIMATE MESSAGE (green)
- **Metrics Grid**: 4 key indicators
  - Prediction (Spam/Ham)
  - Confidence score
  - Spam probability
  - Ham probability
- **Probability Bars**: Visual representation
  - Red bar for spam probability
  - Green bar for ham probability
- **Message Details**:
  - Original length
  - Processed length

### 3. Sample Messages
Four pre-loaded examples:
- **Spam Example 1**: Prize/money scam
- **Ham Example 1**: Personal message
- **Spam Example 2**: Promotional spam
- **Ham Example 2**: Casual conversation

### 4. Information Cards

**About Spam Detection:**
- Real-time SMS analysis
- NLP preprocessing pipeline
- TF-IDF vectorization
- High accuracy classification

**Classification Types:**
- üö® SPAM: Unwanted/promotional messages
- ‚úÖ HAM: Legitimate messages

**Common Spam Indicators:**
- üí∞ Money-related keywords
- üìû Phone numbers and call-to-action
- üîó Suspicious links or URLs
- ‚ö†Ô∏è Urgent/pressure language
- üéÅ Too-good-to-be-true offers

**Model Information:**
- Algorithm: Multinomial Naive Bayes
- Feature Extraction: TF-IDF Vectorization
- Preprocessing: Stemming, Stopword Removal
- Accuracy: ~97%

### Design Features
- **Modern gradient background** (purple theme)
- **Smooth animations** and transitions
- **Card-based layout** for organization
- **Responsive design** for mobile
- **Color-coded results** (red for spam, green for ham)
- **Interactive hover effects**

---

## üõ†Ô∏è Technologies Used

### Backend Technologies
- **Python 3.8+** - Programming language
- **Flask** - Web framework
- **scikit-learn** - Machine learning
- **NLTK** - Natural language processing
- **Pandas** - Data manipulation
- **NumPy** - Numerical operations
- **Pickle** - Model serialization

### Frontend Technologies
- **HTML5** - Structure
- **CSS3** - Styling (custom, gradient backgrounds)
- **JavaScript (ES6)** - Interactivity
- **Fetch API** - Async requests

### NLP Techniques
- **TF-IDF Vectorization** - Feature extraction
- **Porter Stemmer** - Word stemming
- **Stopword Removal** - Text cleaning
- **Tokenization** - Text splitting
- **N-grams** - Phrase patterns (unigrams, bigrams)

### Development Tools
- **Jupyter Notebook** - Model development
- **Matplotlib/Seaborn** - Visualizations
- **Git/GitHub** - Version control

---

## üîß Configuration

### Change Server Port

Edit `app.py`:
```python
# Line ~80
app.run(debug=True, host='0.0.0.0', port=5001)  # Change port
```

### Adjust Model Parameters

Edit `model_training.ipynb`:
```python
# TF-IDF Configuration
tfidf = TfidfVectorizer(
    max_features=5000,  # Increase vocabulary
    ngram_range=(1, 3)  # Add trigrams
)

# Model Configuration
model = MultinomialNB(alpha=0.5)  # Adjust smoothing
```

### Customize Preprocessing

Edit `app.py` preprocessing function:
```python
def preprocess_text(text):
    # Add custom preprocessing steps
    text = text.lower()
    text = remove_emojis(text)  # Custom function
    # ... rest of preprocessing
```

---

## üêõ Troubleshooting

### Common Issues

**1. Model files not found:**
```bash
# Solution: Run model training notebook
jupyter notebook notebooks/model_training.ipynb
# Complete all cells to generate model files
```

**2. Dataset not found:**
```bash
# Ensure dataset is in correct location
ls data/spam.csv  # Should exist

# If missing, download SMS Spam Collection Dataset
# Place in data/ folder
```

**3. Module not found error:**
```bash
# Install missing package
pip install [package-name]

# Or reinstall all dependencies
pip install -r requirements.txt
```

**4. NLTK data error:**
```python
# Download required NLTK data
import nltk
nltk.download('stopwords')
nltk.download('punkt')
```

**5. Port already in use:**
```bash
# Linux/Mac
lsof -ti:5000 | xargs kill -9

# Windows
netstat -ano | findstr :5000
taskkill /PID [PID] /F

# Or change port in app.py
```

**6. Low prediction accuracy:**
```python
# Retrain model with more features
# In model_training.ipynb:
tfidf = TfidfVectorizer(max_features=5000)

# Or try different algorithms
from sklearn.svm import LinearSVC
model = LinearSVC()
```

---

## üéì Learning Outcomes

### Technical Skills Developed

**Natural Language Processing:**
- Text preprocessing techniques
- Feature engineering (TF-IDF)
- Stopword removal strategies
- Stemming and lemmatization
- N-gram modeling

**Machine Learning:**
- Text classification
- Naive Bayes algorithm
- Model training and evaluation
- Cross-validation
- Confusion matrix analysis
- Precision-Recall trade-offs

**Software Engineering:**
- Flask web development
- RESTful API design
- Frontend development (HTML/CSS/JS)
- Code organization and modularity
- Error handling
- Model deployment

**Data Science:**
- Exploratory data analysis
- Data visualization
- Performance metrics
- Model evaluation
- Documentation

### Concepts Applied
- Natural Language Processing
- Text classification
- Supervised learning
- Naive Bayes algorithm
- Cross-validation
- Model serialization
- Web application deployment
- API development

### Key Insights Gained

1. **Text Preprocessing is Crucial**: Clean, well-preprocessed text dramatically improves accuracy
2. **TF-IDF vs Bag of Words**: TF-IDF performs better by weighting word importance
3. **Naive Bayes for Text**: Excellent baseline for text classification tasks
4. **Class Imbalance**: Dataset has 13.4% spam - handling imbalance is important
5. **Feature Selection**: N-grams capture important phrase patterns
6. **Real-world Deployment**: Considerations for production systems

---

## üìà Future Enhancements

### Short-term
- [ ] Add more ML algorithms (SVM, Random Forest, Logistic Regression)
- [ ] Implement model ensemble (voting classifier)
- [ ] Add user feedback mechanism for continuous learning
- [ ] Expand to email spam detection
- [ ] Multi-language support
- [ ] Add confidence thresholds

### Long-term
- [ ] Deploy to cloud (Heroku/AWS/GCP)
- [ ] Real-time model retraining pipeline
- [ ] Chrome extension for SMS/email filtering
- [ ] Mobile app (React Native/Flutter)
- [ ] Database for logging predictions
- [ ] A/B testing framework
- [ ] Admin dashboard for monitoring

### Advanced Features
- [ ] Deep learning models (LSTM, BERT)
- [ ] Transfer learning with pre-trained models
- [ ] Explainable AI (LIME/SHAP) for predictions
- [ ] Active learning for model improvement
- [ ] Anomaly detection for new spam patterns
- [ ] Multi-modal spam detection (text + metadata)

### Frontend Enhancements
- [ ] Real-time typing analysis
- [ ] Batch file upload (CSV)
- [ ] Historical analysis dashboard
- [ ] Export reports to PDF
- [ ] Dark mode toggle
- [ ] Advanced statistics visualization
- [ ] User authentication
- [ ] Feedback submission system

---

## üìù Dataset Information

**SMS Spam Collection Dataset**

**Source:** UCI Machine Learning Repository

**Description:**
- Messages labeled as spam or ham
- Collected from various sources:
  - SMS Spam Corpus v.0.1 Big
  - NUS SMS Corpus
  - Caroline Tag's PhD Thesis
  - SMS Spam Corpus v.0.1 Small

**Preprocessing Steps:**
1. Label encoding (spam=1, ham=0)
2. Text cleaning (lowercase, remove special chars)
3. Tokenization
4. Stopword removal
5. Stemming
6. TF-IDF feature extraction
7. Train-test split (80-20)

**‚ö†Ô∏è Note:** Dataset NOT included in repo due to size. Download separately.

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

**To contribute:**
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## üìÑ License

This project is part of the CodSoft ML Internship program and is meant for educational purposes.

---

## üôè Acknowledgments

- **CodSoft** - For the internship opportunity and project guidance
- **UCI Machine Learning Repository** - For the SMS Spam Collection Dataset
- **scikit-learn** - For comprehensive ML tools
- **NLTK** - For NLP capabilities
- **Flask Community** - For web framework support

---

## üìß Contact

**Chandan Kumar**

- üîó **LinkedIn:** [Your LinkedIn Profile](https://linkedin.com/in/chandan013)
- üíª **GitHub:** [chandank013](https://github.com/chandank013)
- üìß **Email:** your.email@example.com
- üåê **Portfolio:** [Your Portfolio Website](https://yourportfolio.com)

**Feel free to:**
- ‚≠ê Star this repository if helpful
- üîÑ Fork for your own learning
- üì¨ Reach out for collaborations
- üí¨ Connect on LinkedIn

---

## üè∑Ô∏è Tags & Keywords

`spam-detection` `sms-classification` `nlp` `natural-language-processing` `machine-learning` `naive-bayes` `text-classification` `tf-idf` `flask` `python` `scikit-learn` `nltk` `web-application` `real-time-prediction` `codsoft` `internship`

---

## üìä Project Stats

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![License](https://img.shields.io/badge/License-Educational-green.svg)
![Status](https://img.shields.io/badge/Status-Completed-success.svg)
![ML](https://img.shields.io/badge/ML-Classification-orange.svg)
![NLP](https://img.shields.io/badge/NLP-Text%20Processing-blueviolet.svg)
![Accuracy](https://img.shields.io/badge/Accuracy-97%25-brightgreen.svg)

---

## üéØ Quick Links

- [Installation Guide](#installation--setup)
- [Usage Instructions](#usage)
- [Results & Performance](#results)
- [Project Structure](#project-structure)
- [Troubleshooting](#troubleshooting)
- [Web Interface](#web-interface-components)

---

<div align="center">

### ‚≠ê If you found this project helpful, please give it a star! ‚≠ê

**Made with ‚ù§Ô∏è during CodSoft Machine Learning Internship**

**Batch:** December 2025 B68

**#codsoft #machinelearning #nlp #spamdetection #textclassification**

</div>

---

**Last Updated:** December 2025  
**Version:** 1.0  
**Repository:** https://github.com/chandank013/CODSOFT/codsoft_04

---

## üí° Project Highlights

‚ú® **High Accuracy** - 97.1% classification rate  
‚ú® **Real-time Prediction** - Instant SMS analysis  
‚ú® **Modern Web Interface** - Clean, responsive UI  
‚ú® **Production-Ready** - Flask backend + REST API  
‚ú® **NLP Pipeline** - Complete preprocessing workflow  
‚ú® **Well-Documented** - Comprehensive guide and examples  
‚ú® **Sample Messages** - Pre-loaded for quick testing  

---

**Thank you for exploring this project!** üöÄ

For questions or feedback, feel free to reach out via LinkedIn or GitHub.

**Happy Learning! üìö‚ú®**