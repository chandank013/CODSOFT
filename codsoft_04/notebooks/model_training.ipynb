{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8456145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SPAM SMS DETECTION - MODEL TRAINING\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Spam SMS Detection - Model Training\n",
    "# CodSoft ML Internship - Task 4\n",
    "# Author: Chandan Kumar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, roc_curve)\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SPAM SMS DETECTION - MODEL TRAINING\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3643b347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading processed data...\n",
      "‚úÖ Dataset loaded: (5169, 11)\n"
     ]
    }
   ],
   "source": [
    "# Load processed data\n",
    "print(\"\\nüìÇ Loading processed data...\")\n",
    "df = pd.read_csv('../data/spam_processed.csv')\n",
    "print(f\"‚úÖ Dataset loaded: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b5929bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Messages: 5,169\n",
      "   Spam: 653 (12.63%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = df['cleaned_message']\n",
    "y = df['label_encoded']\n",
    "print(f\"   Messages: {len(X):,}\")\n",
    "print(f\"   Spam: {y.sum():,} ({y.sum()/len(y)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a797b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Split: Train=4,135, Test=1,034\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\n‚úÖ Split: Train={len(X_train):,}, Test={len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "740424b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Cleaning data and applying TF-IDF...\n",
      "‚úÖ TF-IDF shape: (4135, 3000)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "print(\"\\nüîÑ Cleaning data and applying TF-IDF...\")\n",
    "\n",
    "# Ensure there are no NaNs in the data (converts NaNs to '')\n",
    "X_train = X_train.fillna('')\n",
    "X_test = X_test.fillna('')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3000, \n",
    "                             ngram_range=(1, 2), \n",
    "                             min_df=2, \n",
    "                             max_df=0.8)\n",
    "\n",
    "# Fit and transform\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"‚úÖ TF-IDF shape: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b69d43d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../artifacts/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save vectorizer\n",
    "joblib.dump(vectorizer, '../artifacts/tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62c6f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Training Naive Bayes...\n",
      "   Accuracy: 0.9681 | Precision: 0.9900 | Recall: 0.7557 | F1: 0.8571\n",
      "\n",
      "üîÑ Training Logistic Regression...\n",
      "   Accuracy: 0.9652 | Precision: 0.9897 | Recall: 0.7328 | F1: 0.8421\n",
      "\n",
      "üîÑ Training Linear SVM...\n",
      "   Accuracy: 0.9787 | Precision: 0.9739 | Recall: 0.8550 | F1: 0.9106\n"
     ]
    }
   ],
   "source": [
    "# Baseline Models\n",
    "results = {}\n",
    "\n",
    "def train_evaluate(model, name, X_tr, y_tr, X_te, y_te):\n",
    "    print(f\"\\nüîÑ Training {name}...\")\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_proba = model.predict_proba(X_te)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    acc = accuracy_score(y_te, y_pred)\n",
    "    prec = precision_score(y_te, y_pred)\n",
    "    rec = recall_score(y_te, y_pred)\n",
    "    f1 = f1_score(y_te, y_pred)\n",
    "    auc = roc_auc_score(y_te, y_proba) if y_proba is not None else None\n",
    "    \n",
    "    print(f\"   Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f}\")\n",
    "    \n",
    "    return {'model': model, 'accuracy': acc, 'precision': prec, \n",
    "            'recall': rec, 'f1_score': f1, 'roc_auc': auc,\n",
    "            'predictions': y_pred, 'probabilities': y_proba}\n",
    "\n",
    "# Train baseline models\n",
    "results['Naive Bayes (Baseline)'] = train_evaluate(\n",
    "    MultinomialNB(), \"Naive Bayes\", X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "results['Logistic Regression (Baseline)'] = train_evaluate(\n",
    "    LogisticRegression(max_iter=1000, random_state=42), \n",
    "    \"Logistic Regression\", X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "\n",
    "results['Linear SVM (Baseline)'] = train_evaluate(\n",
    "    LinearSVC(max_iter=1000, random_state=42), \n",
    "    \"Linear SVM\", X_train_tfidf, y_train, X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e699e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "\n",
      "üîç Tuning Naive Bayes...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "‚úÖ Best: {'alpha': 0.1}, F1: 0.9130\n",
      "\n",
      "üîÑ Training Naive Bayes (Tuned)...\n",
      "   Accuracy: 0.9797 | Precision: 0.9741 | Recall: 0.8626 | F1: 0.9150\n",
      "\n",
      "üîç Tuning Logistic Regression...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "‚úÖ Best: {'C': 10, 'penalty': 'l2'}, F1: 0.9007\n",
      "\n",
      "üîÑ Training Logistic Regression (Tuned)...\n",
      "   Accuracy: 0.9768 | Precision: 0.9735 | Recall: 0.8397 | F1: 0.9016\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Naive Bayes\n",
    "print(\"\\nüîç Tuning Naive Bayes...\")\n",
    "nb_grid = GridSearchCV(MultinomialNB(), {'alpha': [0.1, 0.5, 1.0, 2.0]}, \n",
    "                       cv=3, scoring='f1', n_jobs=2, verbose=1)\n",
    "nb_grid.fit(X_train_tfidf, y_train)\n",
    "print(f\"‚úÖ Best: {nb_grid.best_params_}, F1: {nb_grid.best_score_:.4f}\")\n",
    "\n",
    "results['Naive Bayes (Tuned)'] = train_evaluate(\n",
    "    nb_grid.best_estimator_, \"Naive Bayes (Tuned)\", \n",
    "    X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results['Naive Bayes (Tuned)']['best_params'] = nb_grid.best_params_\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\nüîç Tuning Logistic Regression...\")\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000, random_state=42),\n",
    "    {'C': [0.1, 1, 10], 'penalty': ['l2']}, \n",
    "    cv=3, scoring='f1', n_jobs=2, verbose=1)\n",
    "lr_grid.fit(X_train_tfidf, y_train)\n",
    "print(f\"‚úÖ Best: {lr_grid.best_params_}, F1: {lr_grid.best_score_:.4f}\")\n",
    "\n",
    "results['Logistic Regression (Tuned)'] = train_evaluate(\n",
    "    lr_grid.best_estimator_, \"Logistic Regression (Tuned)\", \n",
    "    X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results['Logistic Regression (Tuned)']['best_params'] = lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb1b15ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ BEST MODEL: Naive Bayes (Tuned)\n",
      "   F1-Score: 0.9150\n",
      "   Precision: 0.9741\n",
      "   Recall: 0.8626\n"
     ]
    }
   ],
   "source": [
    "# Select best model\n",
    "best_name = max([k for k in results.keys() if 'Tuned' in k], \n",
    "                key=lambda x: results[x]['f1_score'])\n",
    "best_model = results[best_name]['model']\n",
    "best_metrics = results[best_name]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_name}\")\n",
    "print(f\"   F1-Score: {best_metrics['f1_score']:.4f}\")\n",
    "print(f\"   Precision: {best_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall: {best_metrics['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f46ffa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model saved: ../models/spam_detector_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save best model\n",
    "joblib.dump(best_model, '../models/spam_detector_model.pkl')\n",
    "print(\"\\n‚úÖ Model saved: ../models/spam_detector_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93d40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_metrics['predictions'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "plt.title(f'Confusion Matrix - {best_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/confusion_matrix_spam.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bcdac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed! All files saved.\n"
     ]
    }
   ],
   "source": [
    "# Save metrics\n",
    "with open('../artifacts/training_metrics.json', 'w') as f:\n",
    "    json.dump({'best_model': best_name, \n",
    "               'metrics': {k: {m: float(v) for m, v in r.items() \n",
    "                              if isinstance(v, (int, float))} \n",
    "                          for k, r in results.items() if 'Tuned' in k}}, f, indent=4)\n",
    "\n",
    "print(\"\\n‚úÖ Training completed! All files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdf31a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codsoft_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
