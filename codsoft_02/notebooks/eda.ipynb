{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fb6761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREDIT CARD FRAUD DETECTION - EXPLORATORY DATA ANALYSIS\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Credit Card Fraud Detection - Exploratory Data Analysis\n",
    "# CodSoft ML Internship - Task 2\n",
    "# Author: Chandan Kumar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CREDIT CARD FRAUD DETECTION - EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd8b6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Loading datasets...\n",
      "‚úÖ Training data loaded: (1296675, 23)\n",
      "‚úÖ Test data loaded: (555719, 23)\n",
      "‚úÖ Dataset loaded successfully!\n",
      "   Shape: (1852394, 23)\n",
      "   Rows: 1,852,394\n",
      "   Columns: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD DATASET\n",
    "\n",
    "print(\"\\nüìÇ Loading datasets...\")\n",
    "# Load training and test data\n",
    "df_train = pd.read_csv('../data/fraudTrain.csv')\n",
    "df_test = pd.read_csv('../data/fraudTest.csv')\n",
    "\n",
    "print(f\"‚úÖ Training data loaded: {df_train.shape}\")\n",
    "print(f\"‚úÖ Test data loaded: {df_test.shape}\")\n",
    "\n",
    "# Combine for EDA (we'll split later for training)\n",
    "df = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"   Shape: {df.shape}\")\n",
    "print(f\"   Rows: {df.shape[0]:,}\")\n",
    "print(f\"   Columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf614ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA OVERVIEW\n",
      "======================================================================\n",
      "\n",
      "üìä First 5 rows:\n",
      "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
      "0           0   2019-01-01 00:00:18  2703186189652095   \n",
      "1           1   2019-01-01 00:00:44      630423337322   \n",
      "2           2   2019-01-01 00:00:51    38859492057661   \n",
      "3           3   2019-01-01 00:01:16  3534093764340240   \n",
      "4           4   2019-01-01 00:03:06   375534208663984   \n",
      "\n",
      "                             merchant       category     amt      first  \\\n",
      "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
      "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
      "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
      "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
      "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
      "\n",
      "      last gender                        street  ...      lat      long  \\\n",
      "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
      "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
      "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
      "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
      "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
      "\n",
      "   city_pop                                job         dob  \\\n",
      "0      3495          Psychologist, counselling  1988-03-09   \n",
      "1       149  Special educational needs teacher  1978-06-21   \n",
      "2      4154        Nature conservation officer  1962-01-19   \n",
      "3      1939                    Patent attorney  1967-01-12   \n",
      "4        99     Dance movement psychotherapist  1986-03-28   \n",
      "\n",
      "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
      "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
      "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
      "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
      "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
      "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
      "\n",
      "   is_fraud  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "üìã Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 23 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Unnamed: 0             int64  \n",
      " 1   trans_date_trans_time  object \n",
      " 2   cc_num                 int64  \n",
      " 3   merchant               object \n",
      " 4   category               object \n",
      " 5   amt                    float64\n",
      " 6   first                  object \n",
      " 7   last                   object \n",
      " 8   gender                 object \n",
      " 9   street                 object \n",
      " 10  city                   object \n",
      " 11  state                  object \n",
      " 12  zip                    int64  \n",
      " 13  lat                    float64\n",
      " 14  long                   float64\n",
      " 15  city_pop               int64  \n",
      " 16  job                    object \n",
      " 17  dob                    object \n",
      " 18  trans_num              object \n",
      " 19  unix_time              int64  \n",
      " 20  merch_lat              float64\n",
      " 21  merch_long             float64\n",
      " 22  is_fraud               int64  \n",
      "dtypes: float64(5), int64(6), object(12)\n",
      "memory usage: 325.1+ MB\n",
      "None\n",
      "\n",
      "üìà Statistical Summary:\n",
      "         Unnamed: 0        cc_num           amt           zip           lat  \\\n",
      "count  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06   \n",
      "mean   5.371934e+05  4.173860e+17  7.006357e+01  4.881326e+04  3.853931e+01   \n",
      "std    3.669110e+05  1.309115e+18  1.592540e+02  2.688185e+04  5.071470e+00   \n",
      "min    0.000000e+00  6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01   \n",
      "25%    2.315490e+05  1.800429e+14  9.640000e+00  2.623700e+04  3.466890e+01   \n",
      "50%    4.630980e+05  3.521417e+15  4.745000e+01  4.817400e+04  3.935430e+01   \n",
      "75%    8.335758e+05  4.642255e+15  8.310000e+01  7.204200e+04  4.194040e+01   \n",
      "max    1.296674e+06  4.992346e+18  2.894890e+04  9.992100e+04  6.669330e+01   \n",
      "\n",
      "               long      city_pop     unix_time     merch_lat    merch_long  \\\n",
      "count  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06   \n",
      "mean  -9.022783e+01  8.864367e+04  1.358674e+09  3.853898e+01 -9.022794e+01   \n",
      "std    1.374789e+01  3.014876e+05  1.819508e+07  5.105604e+00  1.375969e+01   \n",
      "min   -1.656723e+02  2.300000e+01  1.325376e+09  1.902742e+01 -1.666716e+02   \n",
      "25%   -9.679800e+01  7.410000e+02  1.343017e+09  3.474012e+01 -9.689944e+01   \n",
      "50%   -8.747690e+01  2.443000e+03  1.357089e+09  3.936890e+01 -8.744069e+01   \n",
      "75%   -8.015800e+01  2.032800e+04  1.374581e+09  4.195626e+01 -8.024511e+01   \n",
      "max   -6.795030e+01  2.906700e+06  1.388534e+09  6.751027e+01 -6.695090e+01   \n",
      "\n",
      "           is_fraud  \n",
      "count  1.852394e+06  \n",
      "mean   5.210015e-03  \n",
      "std    7.199217e-02  \n",
      "min    0.000000e+00  \n",
      "25%    0.000000e+00  \n",
      "50%    0.000000e+00  \n",
      "75%    0.000000e+00  \n",
      "max    1.000000e+00  \n",
      "\n",
      "üîç Column Name\n",
      "['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant', 'category', 'amt', 'first', 'last', 'gender', 'street', 'city', 'state', 'zip', 'lat', 'long', 'city_pop', 'job', 'dob', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'is_fraud']\n"
     ]
    }
   ],
   "source": [
    "# 2. INITIAL DATA INSPECTION\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìä First 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nüìã Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nüîç Column Name\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61de9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "======================================================================\n",
      "Empty DataFrame\n",
      "Columns: [Missing_Count, Percentage]\n",
      "Index: []\n",
      "‚úÖ No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# 3. MISSING VALUES CHECK\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_values,\n",
    "    'Percentage': missing_percent\n",
    "})\n",
    "\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Total missing values: {missing_values.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc03296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLASS DISTRIBUTION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Transaction Distribution:\n",
      "   Legitimate (0): 1,842,743 (99.4790%)\n",
      "   Fraudulent (1): 9,651 (0.5210%)\n",
      "\n",
      "‚ö†Ô∏è  Imbalance Ratio: 1:191\n",
      "   (For every 1 fraud, there are 191 legitimate transactions)\n",
      "\n",
      "‚úÖ Visualization saved: ../images/class_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# 4. CLASS DISTRIBUTION (FRAUD vs LEGITIMATE)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class_counts = df['is_fraud'].value_counts()\n",
    "class_percentages = df['is_fraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nüìä Transaction Distribution:\")\n",
    "print(f\"   Legitimate (0): {class_counts[0]:,} ({class_percentages[0]:.4f}%)\")\n",
    "print(f\"   Fraudulent (1): {class_counts[1]:,} ({class_percentages[1]:.4f}%)\")\n",
    "\n",
    "fraud_ratio = class_counts[1] / class_counts[0]\n",
    "print(f\"\\n‚ö†Ô∏è  Imbalance Ratio: 1:{1/fraud_ratio:.0f}\")\n",
    "print(f\"   (For every 1 fraud, there are {1/fraud_ratio:.0f} legitimate transactions)\")\n",
    "\n",
    "# Visualization - Class Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(['Legitimate', 'Fraudulent'], class_counts.values, \n",
    "            color=['green', 'red'], alpha=0.7)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Transaction Class Distribution')\n",
    "axes[0].set_yscale('log')  # Log scale due to imbalance\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['lightgreen', 'lightcoral']\n",
    "axes[1].pie(class_counts.values, labels=['Legitimate', 'Fraudulent'], \n",
    "            autopct='%1.4f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Transaction Class Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Visualization saved: ../images/class_distribution.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40352a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TIME ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "‚è±Ô∏è  Time Range:\n",
      "   Min: 1325376018 seconds\n",
      "   Max: 1388534374 seconds\n",
      "   Duration: 385704.0 hours\n",
      "‚úÖ Time analysis saved: ../images/time_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# 5. TIME ANALYSIS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TIME ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Time Range:\")\n",
    "print(f\"   Min: {df['unix_time'].min():.0f} seconds\")\n",
    "print(f\"   Max: {df['unix_time'].max():.0f} seconds\")\n",
    "print(f\"   Duration: {df['unix_time'].max() / 3600:.1f} hours\")\n",
    "\n",
    "# Convert time to hours\n",
    "df['Time_Hour'] = df['unix_time'] / 3600\n",
    "# Fraud distribution over time\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df[df['is_fraud'] == 0]['Time_Hour'], bins=50, alpha=0.7, \n",
    "         label='Legitimate', color='green')\n",
    "plt.hist(df[df['is_fraud'] == 1]['Time_Hour'], bins=50, alpha=0.7, \n",
    "         label='Fraudulent', color='red')\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Transaction Distribution Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fraud_by_hour = df[df['is_fraud'] == 1].groupby(df['Time_Hour'].astype(int)).size()\n",
    "plt.plot(fraud_by_hour.index, fraud_by_hour.values, color='red', marker='o')\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Fraud Count')\n",
    "plt.title('Fraudulent Transactions Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/time_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úÖ Time analysis saved: ../images/time_analysis.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b426bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRANSACTION AMOUNT ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üí∞ Amount Statistics:\n",
      "   Mean: $70.06\n",
      "   Median: $47.45\n",
      "   Min: $1.00\n",
      "   Max: $28948.90\n",
      "   Std Dev: $159.25\n",
      "\n",
      "üí∞ Amount by Class:\n",
      "\n",
      "   Legitimate:\n",
      "      Mean: $67.65\n",
      "      Median: $47.24\n",
      "      Max: $28948.90\n",
      "\n",
      "   Fraudulent:\n",
      "      Mean: $530.66\n",
      "      Median: $390.00\n",
      "      Max: $1376.04\n",
      "\n",
      "‚úÖ Amount analysis saved: ../images/amount_analysis.png\n"
     ]
    }
   ],
   "source": [
    "# 6. AMOUNT ANALYSIS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRANSACTION AMOUNT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí∞ Amount Statistics:\")\n",
    "print(f\"   Mean: ${df['amt'].mean():.2f}\")\n",
    "print(f\"   Median: ${df['amt'].median():.2f}\")\n",
    "print(f\"   Min: ${df['amt'].min():.2f}\")\n",
    "print(f\"   Max: ${df['amt'].max():.2f}\")\n",
    "print(f\"   Std Dev: ${df['amt'].std():.2f}\")\n",
    "print(\"\\nüí∞ Amount by Class:\")\n",
    "for class_label in [0, 1]:\n",
    "    class_name = \"Legitimate\" if class_label == 0 else \"Fraudulent\"\n",
    "    class_data = df[df['is_fraud'] == class_label]['amt']\n",
    "    print(f\"\\n   {class_name}:\")\n",
    "    print(f\"      Mean: ${class_data.mean():.2f}\")\n",
    "    print(f\"      Median: ${class_data.median():.2f}\")\n",
    "    print(f\"      Max: ${class_data.max():.2f}\")\n",
    "\n",
    "# Visualization - Amount Distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Overall distribution\n",
    "axes[0, 0].hist(df['amt'], bins=50, color='blue', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Amount ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Overall Amount Distribution')\n",
    "axes[0, 0].set_xlim([0, 500])  # Focus on common range\n",
    "\n",
    "# Legitimate vs Fraudulent\n",
    "axes[0, 1].hist(df[df['is_fraud'] == 0]['amt'], bins=50, alpha=0.7, \n",
    "                label='Legitimate', color='green')\n",
    "axes[0, 1].hist(df[df['is_fraud'] == 1]['amt'], bins=50, alpha=0.7, \n",
    "                label='Fraudulent', color='red')\n",
    "axes[0, 1].set_xlabel('Amount ($)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Amount Distribution by Class')\n",
    "axes[0, 1].set_xlim([0, 500])\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Box plots\n",
    "box_data = [df[df['is_fraud'] == 0]['amt'], df[df['is_fraud'] == 1]['amt']]\n",
    "axes[1, 0].boxplot(box_data, labels=['Legitimate', 'Fraudulent'])\n",
    "axes[1, 0].set_ylabel('Amount ($)')\n",
    "axes[1, 0].set_title('Amount Distribution (Box Plot)')\n",
    "axes[1, 0].set_ylim([0, 500])\n",
    "\n",
    "# Log scale comparison\n",
    "axes[1, 1].hist(np.log1p(df[df['is_fraud'] == 0]['amt']), bins=50, \n",
    "                alpha=0.7, label='Legitimate', color='green')\n",
    "axes[1, 1].hist(np.log1p(df[df['is_fraud'] == 1]['amt']), bins=50, \n",
    "                alpha=0.7, label='Fraudulent', color='red')\n",
    "axes[1, 1].set_xlabel('Log(Amount + 1)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Amount Distribution (Log Scale)')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/amount_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Amount analysis saved: ../images/amount_analysis.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b3f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NUMERICAL FEATURE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Number of numerical features: 11\n",
      "\n",
      "üìà Numerical Features Statistics:\n",
      "         Unnamed: 0        cc_num           amt           zip           lat  \\\n",
      "count  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06   \n",
      "mean   5.371934e+05  4.173860e+17  7.006357e+01  4.881326e+04  3.853931e+01   \n",
      "std    3.669110e+05  1.309115e+18  1.592540e+02  2.688185e+04  5.071470e+00   \n",
      "min    0.000000e+00  6.041621e+10  1.000000e+00  1.257000e+03  2.002710e+01   \n",
      "25%    2.315490e+05  1.800429e+14  9.640000e+00  2.623700e+04  3.466890e+01   \n",
      "50%    4.630980e+05  3.521417e+15  4.745000e+01  4.817400e+04  3.935430e+01   \n",
      "75%    8.335758e+05  4.642255e+15  8.310000e+01  7.204200e+04  4.194040e+01   \n",
      "max    1.296674e+06  4.992346e+18  2.894890e+04  9.992100e+04  6.669330e+01   \n",
      "\n",
      "               long      city_pop     unix_time     merch_lat    merch_long  \\\n",
      "count  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06  1.852394e+06   \n",
      "mean  -9.022783e+01  8.864367e+04  1.358674e+09  3.853898e+01 -9.022794e+01   \n",
      "std    1.374789e+01  3.014876e+05  1.819508e+07  5.105604e+00  1.375969e+01   \n",
      "min   -1.656723e+02  2.300000e+01  1.325376e+09  1.902742e+01 -1.666716e+02   \n",
      "25%   -9.679800e+01  7.410000e+02  1.343017e+09  3.474012e+01 -9.689944e+01   \n",
      "50%   -8.747690e+01  2.443000e+03  1.357089e+09  3.936890e+01 -8.744069e+01   \n",
      "75%   -8.015800e+01  2.032800e+04  1.374581e+09  4.195626e+01 -8.024511e+01   \n",
      "max   -6.795030e+01  2.906700e+06  1.388534e+09  6.751027e+01 -6.695090e+01   \n",
      "\n",
      "          Time_Hour  \n",
      "count  1.852394e+06  \n",
      "mean   3.774095e+05  \n",
      "std    5.054189e+03  \n",
      "min    3.681600e+05  \n",
      "25%    3.730602e+05  \n",
      "50%    3.769693e+05  \n",
      "75%    3.818282e+05  \n",
      "max    3.857040e+05  \n",
      "\n",
      "üîç Top 10 Features Correlated with Fraud:\n",
      "amt           0.209308\n",
      "Time_Hour     0.013329\n",
      "unix_time     0.013329\n",
      "lat           0.002904\n",
      "merch_lat     0.002778\n",
      "zip           0.002190\n",
      "cc_num        0.001125\n",
      "long          0.001022\n",
      "merch_long    0.000999\n",
      "Unnamed: 0    0.000524\n",
      "dtype: float64\n",
      "\n",
      "‚úÖ Feature analysis saved: ../images/top_numerical_features.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. FEATURE ANALYSIS (NUMERICAL FEATURES)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NUMERICAL FEATURE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select numerical features (excluding target)\n",
    "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_features = numeric_features.drop('is_fraud')\n",
    "\n",
    "print(f\"\\nüìä Number of numerical features: {len(numeric_features)}\")\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nüìà Numerical Features Statistics:\")\n",
    "print(df[numeric_features].describe())\n",
    "\n",
    "# Correlation with fraud\n",
    "print(\"\\nüîç Top 10 Features Correlated with Fraud:\")\n",
    "correlations = df[numeric_features].corrwith(df['is_fraud']).abs().sort_values(ascending=False)\n",
    "print(correlations.head(10))\n",
    "\n",
    "# Visualization - Top correlated features\n",
    "top_features = correlations.head(6).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    axes[idx].hist(\n",
    "        df[df['is_fraud'] == 0][feature],\n",
    "        bins=50, alpha=0.7, label='Legitimate', density=True\n",
    "    )\n",
    "    axes[idx].hist(\n",
    "        df[df['is_fraud'] == 1][feature],\n",
    "        bins=50, alpha=0.7, label='Fraudulent', density=True\n",
    "    )\n",
    "    axes[idx].set_title(f'{feature}\\nCorr: {correlations[feature]:.3f}')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/top_numerical_features.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Feature analysis saved: ../images/top_numerical_features.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a974419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CORRELATION ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üî• Features Most Correlated with Fraud:\n",
      "amt           0.209308\n",
      "unix_time     0.013329\n",
      "Time_Hour     0.013329\n",
      "lat           0.002904\n",
      "merch_lat     0.002778\n",
      "zip           0.002190\n",
      "cc_num        0.001125\n",
      "long          0.001022\n",
      "merch_long    0.000999\n",
      "Unnamed: 0    0.000524\n",
      "city_pop      0.000325\n",
      "Name: is_fraud, dtype: float64\n",
      "\n",
      "‚úÖ Correlation matrix saved: ../images/correlation_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# 8. CORRELATION MATRIX (Numeric Features Only)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Ensure target exists\n",
    "assert 'is_fraud' in numeric_df.columns, \"Target column 'is_fraud' not found\"\n",
    "\n",
    "# Correlation with target\n",
    "feature_correlations = (\n",
    "    numeric_df\n",
    "    .corr()['is_fraud']\n",
    "    .abs()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nüî• Features Most Correlated with Fraud:\")\n",
    "print(feature_correlations.drop('is_fraud').head(15))\n",
    "\n",
    "# Select top features (+ target)\n",
    "top_features = feature_correlations.drop('is_fraud').head(15).index.tolist()\n",
    "top_features.append('is_fraud')\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = numeric_df[top_features].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.title('Correlation Matrix - Top Features vs Fraud')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Ensure directory exists before saving\n",
    "import os\n",
    "os.makedirs('../images', exist_ok=True)\n",
    "\n",
    "plt.savefig('../images/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Correlation matrix saved: ../images/correlation_matrix.png\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbf04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA SCALING\n",
      "======================================================================\n",
      "\n",
      "üîÑ Scaling 'Time' and 'Amount' features...\n",
      "‚úÖ Features scaled successfully!\n",
      "‚úÖ Scaler saved: ../artifacts/scaler.pkl\n",
      "‚úÖ Scaled data saved: ../artifacts/creditcard_scaled.csv\n"
     ]
    }
   ],
   "source": [
    "# 9. DATA SCALING PREPARATION\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüîÑ Scaling 'Time' and 'Amount' features...\")\n",
    "\n",
    "# Create scaled version\n",
    "df_scaled = df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled['amt'] = scaler.fit_transform(df_scaled['amt'].values.reshape(-1, 1))\n",
    "df_scaled['unix_time'] = scaler.fit_transform(df_scaled['unix_time'].values.reshape(-1, 1))\n",
    "\n",
    "print(\"‚úÖ Features scaled successfully!\")\n",
    "\n",
    "# Save scaler for later use\n",
    "import joblib\n",
    "joblib.dump(scaler, '../artifacts/scaler.pkl')\n",
    "print(\"‚úÖ Scaler saved: ../artifacts/scaler.pkl\")\n",
    "\n",
    "# Save scaled data\n",
    "df_scaled.to_csv('../data/creditcard_scaled.csv', index=False)\n",
    "print(\"‚úÖ Scaled data saved: ../data/creditcard_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af1e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY REPORT\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Summary:\n",
      "   Total Transactions: 1852394\n",
      "   Legitimate Transactions: 1842743\n",
      "   Fraudulent Transactions: 9651\n",
      "   Fraud Percentage: 0.5210%\n",
      "   Imbalance Ratio: 1:191\n",
      "   Number of Features: 23\n",
      "   Time Range (hours): 385704.0\n",
      "   Average Amount: $70.06\n",
      "   Max Amount: $28948.90\n",
      "   Top Correlated Feature: amt\n",
      "   Top Correlation Value: 0.2093\n",
      "\n",
      "‚úÖ Summary saved: ../artifacts/eda_summary.json\n",
      "\n",
      "======================================================================\n",
      "KEY INSIGHTS\n",
      "======================================================================\n",
      "\n",
      "üîç Key Findings:\n",
      "\n",
      "1. SEVERE CLASS IMBALANCE\n",
      "   - Only 0.17% of transactions are fraudulent\n",
      "   - This requires special handling (SMOTE, class weights, etc.)\n",
      "\n",
      "2. TIME PATTERNS\n",
      "   - Fraudulent transactions show different time patterns\n",
      "   - Some hours have higher fraud rates\n",
      "\n",
      "3. AMOUNT DIFFERENCES\n",
      "   - Fraudulent transactions tend to have different amount patterns\n",
      "   - Most frauds are in specific amount ranges\n",
      "\n",
      "4. PCA FEATURES\n",
      "   - Several V features show strong correlation with fraud\n",
      "   - Features like V14, V17, V12, V10 are most predictive\n",
      "\n",
      "5. SCALING NEEDED\n",
      "   - Time and Amount need scaling (already done)\n",
      "   - V features are already scaled from PCA\n",
      "\n",
      "6. MODEL RECOMMENDATIONS\n",
      "   - Use techniques for imbalanced data (SMOTE, undersampling)\n",
      "   - Focus on Precision-Recall over Accuracy\n",
      "   - Consider ensemble methods\n",
      "   - Use class weights in models\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ EXPLORATORY DATA ANALYSIS COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   ‚úÖ ../artifacts/class_distribution.png\n",
      "   ‚úÖ ../artifacts/time_analysis.png\n",
      "   ‚úÖ ../artifacts/amount_analysis.png\n",
      "   ‚úÖ ../artifacts/top_features.png\n",
      "   ‚úÖ ../artifacts/correlation_matrix.png\n",
      "   ‚úÖ ../artifacts/scaler.pkl\n",
      "   ‚úÖ ../artifacts/eda_summary.json\n",
      "   ‚úÖ ../data/creditcard_scaled.csv\n",
      "\n",
      "üöÄ Next Steps:\n",
      "   1. Run model_training.ipynb to build fraud detection models\n",
      "   2. Focus on handling class imbalance\n",
      "   3. Optimize for Precision-Recall metrics\n"
     ]
    }
   ],
   "source": [
    "# 10. SUMMARY STATISTICS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = {\n",
    "    'Total Transactions': len(df),\n",
    "    'Legitimate Transactions': int(class_counts[0]),\n",
    "    'Fraudulent Transactions': int(class_counts[1]),\n",
    "    'Fraud Percentage': f\"{class_percentages[1]:.4f}%\",\n",
    "    'Imbalance Ratio': f\"1:{1/fraud_ratio:.0f}\",\n",
    "    'Number of Features': len(df.columns) - 1,\n",
    "    'Time Range (hours)': f\"{df['unix_time'].max() / 3600:.1f}\",\n",
    "    'Average Amount': f\"${df['amt'].mean():.2f}\",\n",
    "    'Max Amount': f\"${df['amt'].max():.2f}\",\n",
    "    'Top Correlated Feature': correlations.head(1).index[0],\n",
    "    'Top Correlation Value': f\"{correlations.head(1).values[0]:.4f}\"\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Dataset Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Save summary\n",
    "import json\n",
    "with open('../artifacts/eda_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "print(\"\\n‚úÖ Summary saved: ../artifacts/eda_summary.json\")\n",
    "\n",
    "# 11. KEY INSIGHTS\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "üîç Key Findings:\n",
    "\n",
    "1. SEVERE CLASS IMBALANCE\n",
    "   - Only 0.17% of transactions are fraudulent\n",
    "   - This requires special handling (SMOTE, class weights, etc.)\n",
    "\n",
    "2. TIME PATTERNS\n",
    "   - Fraudulent transactions show different time patterns\n",
    "   - Some hours have higher fraud rates\n",
    "\n",
    "3. AMOUNT DIFFERENCES\n",
    "   - Fraudulent transactions tend to have different amount patterns\n",
    "   - Most frauds are in specific amount ranges\n",
    "\n",
    "4. PCA FEATURES\n",
    "   - Several V features show strong correlation with fraud\n",
    "   - Features like V14, V17, V12, V10 are most predictive\n",
    "\n",
    "5. SCALING NEEDED\n",
    "   - Time and Amount need scaling (already done)\n",
    "   - V features are already scaled from PCA\n",
    "\n",
    "6. MODEL RECOMMENDATIONS\n",
    "   - Use techniques for imbalanced data (SMOTE, undersampling)\n",
    "   - Focus on Precision-Recall over Accuracy\n",
    "   - Consider ensemble methods\n",
    "   - Use class weights in models\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EXPLORATORY DATA ANALYSIS COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"   ‚úÖ ../artifacts/class_distribution.png\")\n",
    "print(\"   ‚úÖ ../artifacts/time_analysis.png\")\n",
    "print(\"   ‚úÖ ../artifacts/amount_analysis.png\")\n",
    "print(\"   ‚úÖ ../artifacts/top_features.png\")\n",
    "print(\"   ‚úÖ ../artifacts/correlation_matrix.png\")\n",
    "print(\"   ‚úÖ ../artifacts/scaler.pkl\")\n",
    "print(\"   ‚úÖ ../artifacts/eda_summary.json\")\n",
    "print(\"   ‚úÖ ../data/creditcard_scaled.csv\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Run model_training.ipynb to build fraud detection models\")\n",
    "print(\"   2. Focus on handling class imbalance\")\n",
    "print(\"   3. Optimize for Precision-Recall metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4998e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codsoft_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
